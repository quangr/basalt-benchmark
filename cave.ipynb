{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from basalt.config import DefaultDataConfig\n",
    "from basalt.linear_probe import LinearProbe\n",
    "from basalt.config import DefaultDataConfig\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "import tyro\n",
    "from basalt.common import load_model_parameters\n",
    "from basalt.vpt_lib.agent import MineRLAgent\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import torch_xla.core.xla_model as xm\n",
    "from basalt.vpt_lib.agent import resize_image, AGENT_RESOLUTION\n",
    "\n",
    "device = xm.xla_device()\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch_xla\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    data = DefaultDataConfig()\n",
    "    task_name: str = \"MineRLBasaltFindCave-v0/\"\n",
    "\n",
    "\n",
    "args = Args()\n",
    "\n",
    "agent_policy_kwargs, agent_pi_head_kwargs = load_model_parameters(args.data.model_path)\n",
    "\n",
    "\n",
    "def extract_frames(video_path):\n",
    "    \"\"\"\n",
    "    Extract frames at intervals from a video.\n",
    "    \"\"\"\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frames = []\n",
    "    labels = []\n",
    "\n",
    "    timesteps = list(range(0, total_frames, 10))\n",
    "\n",
    "    for timestep in timesteps:\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, timestep)\n",
    "        success, frame = video.read()\n",
    "\n",
    "        if success:\n",
    "            cv2.cvtColor(frame, code=cv2.COLOR_BGR2RGB, dst=frame)\n",
    "            frame = np.asarray(np.clip(frame, 0, 255), dtype=np.uint8)\n",
    "            frame = resize_image(frame, AGENT_RESOLUTION)\n",
    "            frames.append(frame)\n",
    "            labels.append(timestep / total_frames)\n",
    "        else:\n",
    "            print(timestep, video_path)\n",
    "    video.release()\n",
    "    return frames, labels\n",
    "\n",
    "\n",
    "agent = MineRLAgent(\n",
    "    device=device,\n",
    "    policy_kwargs=agent_policy_kwargs,\n",
    "    pi_head_kwargs=agent_pi_head_kwargs,\n",
    ")\n",
    "agent.load_weights(args.data.weights_path)\n",
    "policy = agent.policy\n",
    "policy.eval()\n",
    "\n",
    "net = policy.net\n",
    "video_dir = f\"{args.data.task_data_prefix}/{args.task_name}\"\n",
    "\n",
    "linear_probe = LinearProbe(net.hidsize).to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_probe.load_parameters(\n",
    "    \"checkpoints/linear_probe/MineRLBasaltFindCave-v0/epoch_10.pt\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import torch\n",
    "import torch_xla\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "dir1_files = random.sample(glob.glob(\"/data/quangr/demonstrations/MineRLBasaltMakeWaterfall-v0/*.mp4\"), 2)\n",
    "dir2_files = random.sample(glob.glob(\"/data/quangr/demonstrations/MineRLBasaltFindCave-v0/*.mp4\"), 2)\n",
    "fig, ax = plt.subplots()\n",
    "label_color_mapping = {\n",
    "    \"dir1\": \"red\",\n",
    "    \"dir2\": \"blue\",\n",
    "}\n",
    "handles = []\n",
    "labels = []\n",
    "\n",
    "# Process each selected video file\n",
    "for video_file in dir1_files + dir2_files:\n",
    "    frames = extract_frames(video_file)[0]\n",
    "    frames_tensor = torch.tensor(np.array(frames)).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with torch_xla.step():\n",
    "            output = net.img_preprocess(frames_tensor[:, None].to(device))\n",
    "            output = net.img_process(output).squeeze()\n",
    "\n",
    "    # Get the linear probe output\n",
    "    linear_probe_output = linear_probe(output).detach().cpu().sigmoid()\n",
    "\n",
    "    # Determine label based on directory\n",
    "    if video_file in dir1_files:\n",
    "        video_label = \"dir1\"\n",
    "    else:\n",
    "        video_label = \"dir2\"\n",
    "\n",
    "    # Plot the linear probe output on the same axis with a label\n",
    "    line,=ax.plot(linear_probe_output, label=video_label, color=label_color_mapping[video_label])\n",
    "    if video_label not in labels:\n",
    "        handles.append(line)\n",
    "        labels.append(video_label)\n",
    "\n",
    "    # Insert images at indices where linear_probe_output > 0.5\n",
    "    for i in range(0, len(frames)):\n",
    "        if linear_probe_output[i] > 0.5:\n",
    "            img = OffsetImage(frames[i], zoom=0.2)  # Adjust zoom as needed\n",
    "            ab = AnnotationBbox(img, (i, linear_probe_output[i]), frameon=False)\n",
    "            ax.add_artist(ab)\n",
    "\n",
    "# Adjust plot settings\n",
    "plt.ylim(0, 1)\n",
    "ax.legend()  # Add a legend to the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
